{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce28d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7b4ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movies_tmdb_progres1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df1 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmovies_tmdb_progres1.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb2 = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mmovies_tmdb_progres2.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m df3 = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mmovies_tmdb_progres3.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'movies_tmdb_progres1.csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('movies_tmdb_progres1.csv')\n",
    "df_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb_tmdb2 = pd.read_csv('movies_tmdb_progres2.csv')\n",
    "df3 = pd.read_csv('movies_tmdb_progres3.csv')\n",
    "\n",
    "# Concatenar verticalmente\n",
    "df_tmdb = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Guardar el resultado\n",
    "df_tmdb.to_csv('dataset_tmdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21268e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                       0\n",
       "vote_average                0\n",
       "vote_count                  0\n",
       "release_date                0\n",
       "revenue                     0\n",
       "runtime                     0\n",
       "adult                       0\n",
       "budget                      0\n",
       "imdb_id                     0\n",
       "original_language           0\n",
       "overview                 7520\n",
       "popularity                  0\n",
       "tagline                 78166\n",
       "genres                      0\n",
       "production_companies        0\n",
       "production_countries     5850\n",
       "spoken_languages         9680\n",
       "keywords                    0\n",
       "director                 4052\n",
       "top_actors               8320\n",
       "budget_tmdb               792\n",
       "revenue_tmdb              792\n",
       "runtime_tmdb              792\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb = pd.read_csv('dataset_tmdb.csv')\n",
    "df_tmdb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ba4f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "      <th>director</th>\n",
       "      <th>top_actors</th>\n",
       "      <th>budget_tmdb</th>\n",
       "      <th>revenue_tmdb</th>\n",
       "      <th>runtime_tmdb</th>\n",
       "      <th>overview_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>tagline_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86365</th>\n",
       "      <td>de la piste aux étoiles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt22522248</td>\n",
       "      <td>fr</td>\n",
       "      <td>...</td>\n",
       "      <td>French</td>\n",
       "      <td>formula one (f1), car racing</td>\n",
       "      <td>manu coeman</td>\n",
       "      <td>stéphane de groodt, claude lelouch, esteban oc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>piste aux étoile</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86366</th>\n",
       "      <td>the last american colony</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt11143486</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>revolution, puerto rico, colonization</td>\n",
       "      <td>bestor cram</td>\n",
       "      <td>juan segarra palmer, pedro albizu campos, rafa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>puerto rico relic colonization hemisphere terr...</td>\n",
       "      <td>american colony</td>\n",
       "      <td>man revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86367</th>\n",
       "      <td>postscript</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>3000</td>\n",
       "      <td>tt4931948</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>anthology, apocalypse, horror anthology, post-...</td>\n",
       "      <td>mark garvey</td>\n",
       "      <td>mark garvey, paul woodcock, ian tucknott, emma...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>anthology film set future survivor try stay co...</td>\n",
       "      <td>postscript</td>\n",
       "      <td>future max mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86368</th>\n",
       "      <td>involuntary wingman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt22267742</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>high school, toronto, canada, screwball comedy...</td>\n",
       "      <td>alex ef</td>\n",
       "      <td>abasi ekpenyon, ojonugwa usman, aaron macpherson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>face threat blackmail year david force owen in...</td>\n",
       "      <td>involuntary wingman</td>\n",
       "      <td>celibate involuntary wingman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86369</th>\n",
       "      <td>ricochet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0559627</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>accidental death, military training</td>\n",
       "      <td>marc daniels</td>\n",
       "      <td>dick powell, van heflin, john doucette, john a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>army sergeant blame cause rookie death training</td>\n",
       "      <td>ricochet</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122676</th>\n",
       "      <td>lullaby</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt4071216</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>killer clown</td>\n",
       "      <td>clifford duvernois</td>\n",
       "      <td>dax spanogle, lindsey shaheen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sylvester killer clown leave trail body victim...</td>\n",
       "      <td></td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122677</th>\n",
       "      <td>year of the dragon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1989-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt12007916</td>\n",
       "      <td>et</td>\n",
       "      <td>...</td>\n",
       "      <td>Estonian, Russian</td>\n",
       "      <td>independence movement, perestroika</td>\n",
       "      <td>andres sööt</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>year estonia come surprise symbol allow expres...</td>\n",
       "      <td>year dragon</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122678</th>\n",
       "      <td>the merry mistake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt13567594</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>holiday, christmas, short story, short film</td>\n",
       "      <td>louise alston</td>\n",
       "      <td>geovanni gopradi, jacqi vene, vic polizos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>note self ask santa glass year piper mistook m...</td>\n",
       "      <td>merry mistake</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122679</th>\n",
       "      <td>in one hundred years in may</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986-11-27</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0219286</td>\n",
       "      <td>et</td>\n",
       "      <td>...</td>\n",
       "      <td>Estonian</td>\n",
       "      <td>communist</td>\n",
       "      <td>kaljo kiisk</td>\n",
       "      <td>jüri krjukov, jaan rekkor, arvo kukumägi, sule...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>viktor kingissepp head communist party estonia...</td>\n",
       "      <td>year</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122680</th>\n",
       "      <td>no festival</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt12798264</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>Romanian</td>\n",
       "      <td>music festival, romania</td>\n",
       "      <td>dorin marcu</td>\n",
       "      <td>adrian despot, mihai ristea, alexe marius andrei</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>pandemic castle music festival shift concert s...</td>\n",
       "      <td>festival</td>\n",
       "      <td>concert concert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36316 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  vote_average  vote_count release_date  \\\n",
       "86365       de la piste aux étoiles           0.0           0   2023-10-22   \n",
       "86366      the last american colony           0.0           0   2019-10-18   \n",
       "86367                    postscript           0.0           0   2016-01-01   \n",
       "86368           involuntary wingman           0.0           0   2022-10-01   \n",
       "86369                      ricochet           0.0           0   1961-10-03   \n",
       "...                             ...           ...         ...          ...   \n",
       "122676                      lullaby           0.0           0   2014-10-22   \n",
       "122677           year of the dragon           0.0           0   1989-02-01   \n",
       "122678            the merry mistake           0.0           0   2020-12-25   \n",
       "122679  in one hundred years in may           0.0           0   1986-11-27   \n",
       "122680                  no festival           0.0           0   2020-12-01   \n",
       "\n",
       "        revenue  runtime  adult  budget     imdb_id original_language  ...  \\\n",
       "86365         0        0  False       0  tt22522248                fr  ...   \n",
       "86366         0       90  False       0  tt11143486                en  ...   \n",
       "86367         0       90  False    3000   tt4931948                en  ...   \n",
       "86368         0        8  False       0  tt22267742                en  ...   \n",
       "86369         0       60  False       0   tt0559627                en  ...   \n",
       "...         ...      ...    ...     ...         ...               ...  ...   \n",
       "122676        0        0  False       0   tt4071216                en  ...   \n",
       "122677        0       58  False       0  tt12007916                et  ...   \n",
       "122678        0       15  False       0  tt13567594                en  ...   \n",
       "122679        0       92  False       0   tt0219286                et  ...   \n",
       "122680        0       92  False       0  tt12798264                en  ...   \n",
       "\n",
       "         spoken_languages                                           keywords  \\\n",
       "86365              French                       formula one (f1), car racing   \n",
       "86366    English, Spanish              revolution, puerto rico, colonization   \n",
       "86367             English  anthology, apocalypse, horror anthology, post-...   \n",
       "86368             English  high school, toronto, canada, screwball comedy...   \n",
       "86369             English                accidental death, military training   \n",
       "...                   ...                                                ...   \n",
       "122676                NaN                                       killer clown   \n",
       "122677  Estonian, Russian                 independence movement, perestroika   \n",
       "122678                NaN        holiday, christmas, short story, short film   \n",
       "122679           Estonian                                          communist   \n",
       "122680           Romanian                            music festival, romania   \n",
       "\n",
       "                  director                                         top_actors  \\\n",
       "86365          manu coeman  stéphane de groodt, claude lelouch, esteban oc...   \n",
       "86366          bestor cram  juan segarra palmer, pedro albizu campos, rafa...   \n",
       "86367          mark garvey  mark garvey, paul woodcock, ian tucknott, emma...   \n",
       "86368              alex ef   abasi ekpenyon, ojonugwa usman, aaron macpherson   \n",
       "86369         marc daniels  dick powell, van heflin, john doucette, john a...   \n",
       "...                    ...                                                ...   \n",
       "122676  clifford duvernois                      dax spanogle, lindsey shaheen   \n",
       "122677         andres sööt                                                      \n",
       "122678       louise alston          geovanni gopradi, jacqi vene, vic polizos   \n",
       "122679         kaljo kiisk  jüri krjukov, jaan rekkor, arvo kukumägi, sule...   \n",
       "122680         dorin marcu   adrian despot, mihai ristea, alexe marius andrei   \n",
       "\n",
       "       budget_tmdb revenue_tmdb runtime_tmdb  \\\n",
       "86365          0.0          0.0          0.0   \n",
       "86366          0.0          0.0         90.0   \n",
       "86367       3000.0          0.0         90.0   \n",
       "86368          0.0          0.0          8.0   \n",
       "86369          0.0          0.0         60.0   \n",
       "...            ...          ...          ...   \n",
       "122676         0.0          0.0          0.0   \n",
       "122677         0.0          0.0         58.0   \n",
       "122678         0.0          0.0         15.0   \n",
       "122679         0.0          0.0         92.0   \n",
       "122680         0.0          0.0         92.0   \n",
       "\n",
       "                                           overview_clean  \\\n",
       "86365                                                       \n",
       "86366   puerto rico relic colonization hemisphere terr...   \n",
       "86367   anthology film set future survivor try stay co...   \n",
       "86368   face threat blackmail year david force owen in...   \n",
       "86369     army sergeant blame cause rookie death training   \n",
       "...                                                   ...   \n",
       "122676  sylvester killer clown leave trail body victim...   \n",
       "122677  year estonia come surprise symbol allow expres...   \n",
       "122678  note self ask santa glass year piper mistook m...   \n",
       "122679  viktor kingissepp head communist party estonia...   \n",
       "122680  pandemic castle music festival shift concert s...   \n",
       "\n",
       "                title_clean                 tagline_clean  \n",
       "86365      piste aux étoile                                \n",
       "86366       american colony                man revolution  \n",
       "86367            postscript                future max mad  \n",
       "86368   involuntary wingman  celibate involuntary wingman  \n",
       "86369              ricochet                                \n",
       "...                     ...                           ...  \n",
       "122676                                               safe  \n",
       "122677          year dragon                                \n",
       "122678        merry mistake                                \n",
       "122679                 year                                \n",
       "122680             festival               concert concert  \n",
       "\n",
       "[36316 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb[df_tmdb['vote_count'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5286079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122681/122681 [08:26<00:00, 242.28it/s]\n",
      "100%|██████████| 122681/122681 [03:46<00:00, 542.14it/s]\n",
      "100%|██████████| 122681/122681 [01:37<00:00, 1254.10it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 806541.55it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 292764.83it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 882967.05it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 330407.27it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 785473.62it/s]\n",
      "100%|██████████| 122681/122681 [00:00<00:00, 659034.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "      <th>director</th>\n",
       "      <th>top_actors</th>\n",
       "      <th>budget_tmdb</th>\n",
       "      <th>revenue_tmdb</th>\n",
       "      <th>runtime_tmdb</th>\n",
       "      <th>overview_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>tagline_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>825532764</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "      <td>160000000</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French, Japanese, Swahili</td>\n",
       "      <td>rescue, mission, dream, airplane, paris, franc...</td>\n",
       "      <td>christopher nolan</td>\n",
       "      <td>leonardo dicaprio, joseph gordon-levitt, ken w...</td>\n",
       "      <td>160000000.0</td>\n",
       "      <td>8.390306e+08</td>\n",
       "      <td>148.0</td>\n",
       "      <td>cobb thief commit espionage infiltrate subcons...</td>\n",
       "      <td>inception</td>\n",
       "      <td>mind scene crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>701729206</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "      <td>165000000</td>\n",
       "      <td>tt0816692</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>rescue, future, spacecraft, race against time,...</td>\n",
       "      <td>christopher nolan</td>\n",
       "      <td>matthew mcconaughey, anne hathaway, michael ca...</td>\n",
       "      <td>165000000.0</td>\n",
       "      <td>7.466067e+08</td>\n",
       "      <td>169.0</td>\n",
       "      <td>adventure group explorer use discover wormhole...</td>\n",
       "      <td>interstellar</td>\n",
       "      <td>mankind bear earth mean die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the dark knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>1004558444</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>185000000</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>joker, sadism, chaos, secret identity, crime f...</td>\n",
       "      <td>christopher nolan</td>\n",
       "      <td>christian bale, heath ledger, aaron eckhart, m...</td>\n",
       "      <td>185000000.0</td>\n",
       "      <td>1.004558e+09</td>\n",
       "      <td>152.0</td>\n",
       "      <td>batman raise stake war crime help lt jim gordo...</td>\n",
       "      <td>dark knight</td>\n",
       "      <td>welcome world rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>2923706026</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>237000000</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>future, society, culture clash, space travel, ...</td>\n",
       "      <td>james cameron</td>\n",
       "      <td>sam worthington, zoe saldaña, sigourney weaver...</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2.923706e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>century marine dispatch moon pandora mission t...</td>\n",
       "      <td>avatar</td>\n",
       "      <td>enter world pandora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>220000000</td>\n",
       "      <td>tt0848228</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Hindi, Russian</td>\n",
       "      <td>new york city, superhero, shield, based on com...</td>\n",
       "      <td>joss whedon</td>\n",
       "      <td>robert downey jr., chris evans, mark ruffalo, ...</td>\n",
       "      <td>220000000.0</td>\n",
       "      <td>1.518816e+09</td>\n",
       "      <td>143.0</td>\n",
       "      <td>enemy emerge threaten safety security nick fur...</td>\n",
       "      <td>avenger</td>\n",
       "      <td>assembly require</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  vote_average  vote_count release_date     revenue  \\\n",
       "0        inception         8.364       34495   2010-07-15   825532764   \n",
       "1     interstellar         8.417       32571   2014-11-05   701729206   \n",
       "2  the dark knight         8.512       30619   2008-07-16  1004558444   \n",
       "3           avatar         7.573       29815   2009-12-15  2923706026   \n",
       "4     the avengers         7.710       29166   2012-04-25  1518815515   \n",
       "\n",
       "   runtime  adult     budget    imdb_id original_language  ...  \\\n",
       "0      148  False  160000000  tt1375666                en  ...   \n",
       "1      169  False  165000000  tt0816692                en  ...   \n",
       "2      152  False  185000000  tt0468569                en  ...   \n",
       "3      162  False  237000000  tt0499549                en  ...   \n",
       "4      143  False  220000000  tt0848228                en  ...   \n",
       "\n",
       "                     spoken_languages  \\\n",
       "0  English, French, Japanese, Swahili   \n",
       "1                             English   \n",
       "2                   English, Mandarin   \n",
       "3                    English, Spanish   \n",
       "4             English, Hindi, Russian   \n",
       "\n",
       "                                            keywords           director  \\\n",
       "0  rescue, mission, dream, airplane, paris, franc...  christopher nolan   \n",
       "1  rescue, future, spacecraft, race against time,...  christopher nolan   \n",
       "2  joker, sadism, chaos, secret identity, crime f...  christopher nolan   \n",
       "3  future, society, culture clash, space travel, ...      james cameron   \n",
       "4  new york city, superhero, shield, based on com...        joss whedon   \n",
       "\n",
       "                                          top_actors  budget_tmdb  \\\n",
       "0  leonardo dicaprio, joseph gordon-levitt, ken w...  160000000.0   \n",
       "1  matthew mcconaughey, anne hathaway, michael ca...  165000000.0   \n",
       "2  christian bale, heath ledger, aaron eckhart, m...  185000000.0   \n",
       "3  sam worthington, zoe saldaña, sigourney weaver...  237000000.0   \n",
       "4  robert downey jr., chris evans, mark ruffalo, ...  220000000.0   \n",
       "\n",
       "   revenue_tmdb runtime_tmdb  \\\n",
       "0  8.390306e+08        148.0   \n",
       "1  7.466067e+08        169.0   \n",
       "2  1.004558e+09        152.0   \n",
       "3  2.923706e+09        162.0   \n",
       "4  1.518816e+09        143.0   \n",
       "\n",
       "                                      overview_clean   title_clean  \\\n",
       "0  cobb thief commit espionage infiltrate subcons...     inception   \n",
       "1  adventure group explorer use discover wormhole...  interstellar   \n",
       "2  batman raise stake war crime help lt jim gordo...   dark knight   \n",
       "3  century marine dispatch moon pandora mission t...        avatar   \n",
       "4  enemy emerge threaten safety security nick fur...       avenger   \n",
       "\n",
       "                 tagline_clean  \n",
       "0             mind scene crime  \n",
       "1  mankind bear earth mean die  \n",
       "2           welcome world rule  \n",
       "3          enter world pandora  \n",
       "4             assembly require  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import joblib\n",
    "from scipy import sparse\n",
    "\n",
    "# Cargar modelo de spaCy sin parser ni NER\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "tqdm.pandas()\n",
    "# 1. Rellenar nulos y limpiar tagline y keywords\n",
    "for col in ['keywords', 'tagline', 'title', 'overview', 'top_actors', 'director', 'production_companies']:\n",
    "    df_tmdb[col] = df_tmdb[col].fillna('').str.strip().str.lower()\n",
    "# 2. Función general para limpiar texto usando POS y lematización\n",
    "def clean_text_spacy(text, pos_tags):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(\n",
    "        token.lemma_.lower()  # Usamos la raíz léxica (lemma) en lugar del token original\n",
    "        for token in doc\n",
    "        if token.pos_ in pos_tags and token.is_alpha and not token.is_stop\n",
    "    )\n",
    "# 3. Limpiar overview: solo NOUN, VERB, PROPN\n",
    "df_tmdb['overview'] = df_tmdb['overview'].fillna('')\n",
    "df_tmdb['overview_clean'] = df_tmdb['overview'].progress_apply(lambda x: clean_text_spacy(x, ['NOUN', 'VERB', 'PROPN']))\n",
    "# 4. Limpiar title: NOUN, VERB, PROPN, ADJ\n",
    "df_tmdb['title'] = df_tmdb['title'].fillna('')\n",
    "df_tmdb['title_clean'] = df_tmdb['title'].progress_apply(lambda x: clean_text_spacy(x, ['NOUN', 'VERB', 'PROPN', 'ADJ']))\n",
    "df_tmdb['tagline'] = df_tmdb['tagline'].fillna('')\n",
    "df_tmdb['tagline_clean'] = df_tmdb['tagline'].progress_apply(lambda x: clean_text_spacy(x, ['NOUN', 'VERB', 'PROPN', 'ADJ']))\n",
    "\n",
    "\n",
    "# 6. Eliminar duplicados de palabras por fila\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    return \" \".join(dict.fromkeys(text.split()))\n",
    "for col in ['title_clean', 'overview_clean', 'tagline_clean', 'top_actors', 'director', 'production_companies']:\n",
    "    df_tmdb[col] = df_tmdb[col].progress_apply(remove_duplicates)\n",
    "\n",
    "\n",
    "df_tmdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4983a1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "      <th>director</th>\n",
       "      <th>top_actors</th>\n",
       "      <th>budget_tmdb</th>\n",
       "      <th>revenue_tmdb</th>\n",
       "      <th>runtime_tmdb</th>\n",
       "      <th>overview_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>tagline_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13177</th>\n",
       "      <td>lion of the desert</td>\n",
       "      <td>7.300</td>\n",
       "      <td>147</td>\n",
       "      <td>1981-04-17</td>\n",
       "      <td>1500000</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>35000000</td>\n",
       "      <td>tt0081059</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Arabic, Italian</td>\n",
       "      <td>guerrilla warfare, libya, italy, resistance, w...</td>\n",
       "      <td>moustapha akkad</td>\n",
       "      <td>anthony quinn, rod steiger, oliver reed, irene...</td>\n",
       "      <td>35000000.0</td>\n",
       "      <td>1502136.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>movie tell story omar mukhtar rebel fight conq...</td>\n",
       "      <td>lion desert</td>\n",
       "      <td>man honor war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103441</th>\n",
       "      <td>wedding festivities</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1913-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt3550098</td>\n",
       "      <td>zh</td>\n",
       "      <td>...</td>\n",
       "      <td>No Language</td>\n",
       "      <td>silent film</td>\n",
       "      <td>zheng zhengqiu</td>\n",
       "      <td>wang bing-seng, 丁楚鹤, 黄小雅, 顾静鹤, 张双宜, 杨润身, 胡恨生, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td></td>\n",
       "      <td>wedding festivity</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19839</th>\n",
       "      <td>sheep &amp; wolves: pig deal</td>\n",
       "      <td>6.684</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>3393975</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt8761814</td>\n",
       "      <td>ru</td>\n",
       "      <td>...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>friendship, wolf, friends</td>\n",
       "      <td>vladimir nikolaev</td>\n",
       "      <td>elizaveta boyarskaya, maksim matveev, galina k...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3393975.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>united town sheep wolf live life guest turn fo...</td>\n",
       "      <td>sheep wolf pig deal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24004</th>\n",
       "      <td>the free world</td>\n",
       "      <td>5.989</td>\n",
       "      <td>47</td>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt3517044</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>ex-con, abusive husband, unhappy marriage</td>\n",
       "      <td>jason lew</td>\n",
       "      <td>boyd holbrook, elisabeth moss, octavia spencer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>follow release stretch prison crime commit mo ...</td>\n",
       "      <td>free world</td>\n",
       "      <td>love set free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49621</th>\n",
       "      <td>bermuda island</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt14926914</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>monsters of the wild, tropical island, plane c...</td>\n",
       "      <td>adam werth</td>\n",
       "      <td>tom sizemore, noel gugliemi, john wells, sarah...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>passenger way paradise crash sea find island s...</td>\n",
       "      <td>bermuda island</td>\n",
       "      <td>strand paradise sun go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72080</th>\n",
       "      <td>on the sunny side of the alps</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt1839569</td>\n",
       "      <td>sl</td>\n",
       "      <td>...</td>\n",
       "      <td>Slovenian</td>\n",
       "      <td>short film</td>\n",
       "      <td>janez burger</td>\n",
       "      <td>samuel camara, aisha ibrahim maiga, dado kebe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>family live alpine idyll neighbor buy car</td>\n",
       "      <td>sunny alp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104566</th>\n",
       "      <td>talent agency</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0106229</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>sleazy giallo</td>\n",
       "      <td>ninì grassia</td>\n",
       "      <td>saverio vallone, alex damiani, daniela paganin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>james director george owner film studio mornin...</td>\n",
       "      <td>talent agency</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20853</th>\n",
       "      <td>the student of prague</td>\n",
       "      <td>6.000</td>\n",
       "      <td>62</td>\n",
       "      <td>1913-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0003419</td>\n",
       "      <td>de</td>\n",
       "      <td>...</td>\n",
       "      <td>No Language</td>\n",
       "      <td>prague, czech republic, mysterious man, silent...</td>\n",
       "      <td>stellan rye</td>\n",
       "      <td>paul wegener, grete berger, lyda salmonova, jo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>prague bohemia balduin student fall love margi...</td>\n",
       "      <td>student prague</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107624</th>\n",
       "      <td>striker's mountain</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1985-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>tt0090091</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>canada, helicopter, mountain, snow, snow skiin...</td>\n",
       "      <td>alan simmonds</td>\n",
       "      <td>leslie nielsen, august schellenberg, mimi kuzy...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>construction conglomerate head millionaire wan...</td>\n",
       "      <td>striker mountain</td>\n",
       "      <td>man mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96124</th>\n",
       "      <td>inhumanities</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1989-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0261748</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true crime, mondo</td>\n",
       "      <td>harvey keith</td>\n",
       "      <td>marc andrews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>compilation newsreel footage death scene</td>\n",
       "      <td>inhumanity</td>\n",
       "      <td>ultimate death experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  vote_average  vote_count release_date  \\\n",
       "13177              lion of the desert         7.300         147   1981-04-17   \n",
       "103441            wedding festivities         0.000           0   1913-09-29   \n",
       "19839        sheep & wolves: pig deal         6.684          68   2019-01-24   \n",
       "24004                  the free world         5.989          47   2016-09-23   \n",
       "49621                  bermuda island         3.000           4   2023-01-20   \n",
       "72080   on the sunny side of the alps         7.000           1   2008-01-01   \n",
       "104566                  talent agency         0.000           0   1993-01-01   \n",
       "20853           the student of prague         6.000          62   1913-08-22   \n",
       "107624             striker's mountain         0.000           0   1985-11-01   \n",
       "96124                    inhumanities         0.000           0   1989-01-01   \n",
       "\n",
       "        revenue  runtime  adult    budget     imdb_id original_language  ...  \\\n",
       "13177   1500000      173  False  35000000   tt0081059                en  ...   \n",
       "103441        0       40  False         0   tt3550098                zh  ...   \n",
       "19839   3393975       80  False         0   tt8761814                ru  ...   \n",
       "24004         0      100  False         0   tt3517044                en  ...   \n",
       "49621         0        0  False         0  tt14926914                en  ...   \n",
       "72080         0       15  False         0   tt1839569                sl  ...   \n",
       "104566        0       85  False         0   tt0106229                it  ...   \n",
       "20853         0       85  False         0   tt0003419                de  ...   \n",
       "107624        0       99  False         2   tt0090091                en  ...   \n",
       "96124         0       70  False         0   tt0261748                en  ...   \n",
       "\n",
       "                spoken_languages  \\\n",
       "13177   English, Arabic, Italian   \n",
       "103441               No Language   \n",
       "19839                    Russian   \n",
       "24004                    English   \n",
       "49621                    English   \n",
       "72080                  Slovenian   \n",
       "104566                   Italian   \n",
       "20853                No Language   \n",
       "107624                   English   \n",
       "96124                        NaN   \n",
       "\n",
       "                                                 keywords           director  \\\n",
       "13177   guerrilla warfare, libya, italy, resistance, w...    moustapha akkad   \n",
       "103441                                        silent film     zheng zhengqiu   \n",
       "19839                           friendship, wolf, friends  vladimir nikolaev   \n",
       "24004           ex-con, abusive husband, unhappy marriage          jason lew   \n",
       "49621   monsters of the wild, tropical island, plane c...         adam werth   \n",
       "72080                                          short film       janez burger   \n",
       "104566                                      sleazy giallo       ninì grassia   \n",
       "20853   prague, czech republic, mysterious man, silent...        stellan rye   \n",
       "107624  canada, helicopter, mountain, snow, snow skiin...      alan simmonds   \n",
       "96124                                   true crime, mondo       harvey keith   \n",
       "\n",
       "                                               top_actors budget_tmdb  \\\n",
       "13177   anthony quinn, rod steiger, oliver reed, irene...  35000000.0   \n",
       "103441  wang bing-seng, 丁楚鹤, 黄小雅, 顾静鹤, 张双宜, 杨润身, 胡恨生, ...         0.0   \n",
       "19839   elizaveta boyarskaya, maksim matveev, galina k...         0.0   \n",
       "24004   boyd holbrook, elisabeth moss, octavia spencer...         0.0   \n",
       "49621   tom sizemore, noel gugliemi, john wells, sarah...         0.0   \n",
       "72080   samuel camara, aisha ibrahim maiga, dado kebe ...         0.0   \n",
       "104566  saverio vallone, alex damiani, daniela paganin...         0.0   \n",
       "20853   paul wegener, grete berger, lyda salmonova, jo...         0.0   \n",
       "107624  leslie nielsen, august schellenberg, mimi kuzy...         2.0   \n",
       "96124                                        marc andrews         0.0   \n",
       "\n",
       "       revenue_tmdb runtime_tmdb  \\\n",
       "13177     1502136.0        173.0   \n",
       "103441          0.0         40.0   \n",
       "19839     3393975.0         80.0   \n",
       "24004           0.0        100.0   \n",
       "49621           0.0         86.0   \n",
       "72080           0.0         15.0   \n",
       "104566          0.0         85.0   \n",
       "20853           0.0         85.0   \n",
       "107624          0.0         99.0   \n",
       "96124           0.0         70.0   \n",
       "\n",
       "                                           overview_clean  \\\n",
       "13177   movie tell story omar mukhtar rebel fight conq...   \n",
       "103441                                                      \n",
       "19839   united town sheep wolf live life guest turn fo...   \n",
       "24004   follow release stretch prison crime commit mo ...   \n",
       "49621   passenger way paradise crash sea find island s...   \n",
       "72080           family live alpine idyll neighbor buy car   \n",
       "104566  james director george owner film studio mornin...   \n",
       "20853   prague bohemia balduin student fall love margi...   \n",
       "107624  construction conglomerate head millionaire wan...   \n",
       "96124            compilation newsreel footage death scene   \n",
       "\n",
       "                title_clean              tagline_clean  \n",
       "13177           lion desert              man honor war  \n",
       "103441    wedding festivity                             \n",
       "19839   sheep wolf pig deal                             \n",
       "24004            free world              love set free  \n",
       "49621        bermuda island     strand paradise sun go  \n",
       "72080             sunny alp                             \n",
       "104566        talent agency                             \n",
       "20853        student prague                             \n",
       "107624     striker mountain               man mountain  \n",
       "96124            inhumanity  ultimate death experience  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1b3f930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122681, 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c51e4c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    object\n",
       "vote_average            float64\n",
       "vote_count                int64\n",
       "release_date             object\n",
       "revenue                   int64\n",
       "runtime                   int64\n",
       "adult                      bool\n",
       "budget                    int64\n",
       "imdb_id                  object\n",
       "original_language        object\n",
       "overview                 object\n",
       "popularity              float64\n",
       "tagline                  object\n",
       "genres                   object\n",
       "production_companies     object\n",
       "production_countries     object\n",
       "spoken_languages         object\n",
       "keywords                 object\n",
       "director                 object\n",
       "top_actors               object\n",
       "budget_tmdb             float64\n",
       "revenue_tmdb            float64\n",
       "runtime_tmdb            float64\n",
       "overview_clean           object\n",
       "title_clean              object\n",
       "tagline_clean            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e4ce622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizando columna: title_clean\n",
      "  Entradas vacías: 2721 de 122681\n",
      "Vectorizando columna: overview_clean\n",
      "  Entradas vacías: 7531 de 122681\n",
      "Vectorizando columna: tagline_clean\n",
      "  Entradas vacías: 78644 de 122681\n",
      "Vectorizando columna: keywords\n",
      "  Entradas vacías: 0 de 122681\n",
      "Vectorizando columna: top_actors\n",
      "  Entradas vacías: 8320 de 122681\n",
      "Vectorizando columna: director\n",
      "  Entradas vacías: 4052 de 122681\n",
      "Vectorizando columna: production_companies\n",
      "  Entradas vacías: 0 de 122681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "columnas_vectorizadas = ['title_clean', 'overview_clean', 'tagline_clean', 'keywords', 'top_actors', 'director', 'production_companies']\n",
    "for col in columnas_vectorizadas:\n",
    "    print(f\"Vectorizando columna: {col}\")\n",
    "    \n",
    "    texts = df_tmdb[col].fillna('').astype(str)\n",
    "\n",
    "    # Diagnóstico\n",
    "    empty_count = (texts.str.strip() == '').sum()\n",
    "    print(f\"  Entradas vacías: {empty_count} de {len(texts)}\")\n",
    "    \n",
    "    if empty_count == len(texts):\n",
    "        print(f\"  ❌ Todos los textos en {col} están vacíos. Se omite.\")\n",
    "        continue\n",
    "\n",
    "    # Vectorizar\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, lowercase=True)\n",
    "    vocab_vect = vectorizer.fit_transform(texts)\n",
    "\n",
    "    # Guardar vectores y vectorizador\n",
    "    \n",
    "    joblib.dump(vectorizer, f\"{col}_vect.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d7e069e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122681, 26)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f9a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columnas_vectorizadas:\n\u001b[32m      5\u001b[39m     vectorizer = TfidfVectorizer(max_features=\u001b[32m10000\u001b[39m, lowercase=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     vocab_vect = \u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tmdb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     sparse.save_npz(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{col}\u001b[39;00m\u001b[33m.npz\u001b[39m\u001b[33m'\u001b[39m, vocab_vect)\n\u001b[32m      8\u001b[39m     joblib.dump(vectorizer, \u001b[33m'\u001b[39m\u001b[38;5;132;01m{col}\u001b[39;00m\u001b[33m_vect.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:2104\u001b[39m, in \u001b[36mTfidfVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params()\n\u001b[32m   2098\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf = TfidfTransformer(\n\u001b[32m   2099\u001b[39m     norm=\u001b[38;5;28mself\u001b[39m.norm,\n\u001b[32m   2100\u001b[39m     use_idf=\u001b[38;5;28mself\u001b[39m.use_idf,\n\u001b[32m   2101\u001b[39m     smooth_idf=\u001b[38;5;28mself\u001b[39m.smooth_idf,\n\u001b[32m   2102\u001b[39m     sublinear_tf=\u001b[38;5;28mself\u001b[39m.sublinear_tf,\n\u001b[32m   2103\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2104\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf.fit(X)\n\u001b[32m   2106\u001b[39m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[32m   2107\u001b[39m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1376\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1368\u001b[39m             warnings.warn(\n\u001b[32m   1369\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUpper case characters found in\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m vocabulary while \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlowercase\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m is True. These entries will not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m be matched with any documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1373\u001b[39m             )\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m vocabulary, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1379\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1282\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1280\u001b[39m     vocabulary = \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1284\u001b[39m         )\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indptr[-\u001b[32m1\u001b[39m] > np.iinfo(np.int32).max:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[31mValueError\u001b[39m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "columnas_vectorizadas = ['title_clean', 'overview_clean', 'tagline_clean', 'keywords', 'top_actors', 'director', 'production_companies']\n",
    "\n",
    "# 7. Vectorización TF-IDF\n",
    "for col in columnas_vectorizadas:\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, lowercase=True)\n",
    "    vocab_vect = vectorizer.fit_transform(df_tmdb[col].apply(lambda x: ' '.join(x)))\n",
    "    sparse.save_npz('{col}.npz', vocab_vect)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26e665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb.drop(columns=['overview', 'title', 'tagline', 'keywords', 'overview_clean', 'title_clean', 'tagline_clean', 'top_actors', 'director', 'production_companies'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278bed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando columna: genres\n",
      "Procesando columna: spoken_languages\n",
      "Procesando columna: production_countries\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import joblib\n",
    "import pandas as pd\n",
    "# 1. Función para separar y limpiar strings\n",
    "def split_and_clean(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return []\n",
    "    return [item.strip() for item in text.split(\",\") if item.strip()]\n",
    "# 2. Procesar columnas deseadas\n",
    "cols_to_encode = ['genres', 'spoken_languages', 'production_countries']\n",
    "for col in cols_to_encode:\n",
    "    df_tmdb[col] = df_tmdb[col].apply(split_and_clean)\n",
    "# 3. Binarizar cada columna con MultiLabelBinarizer\n",
    "for col in cols_to_encode:\n",
    "    print(f\"Procesando columna: {col}\")\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    encoded = mlb.fit_transform(df_tmdb[col])\n",
    "    # Guardar binarizador\n",
    "    joblib.dump(mlb, f\"{col}_mlb.pkl\")\n",
    "    # Convertir a DataFrame\n",
    "    encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded, index=df_tmdb.index, columns=[f\"{col}_{cls}\" for cls in mlb.classes_])\n",
    "    # Concatenar con el DataFrame original (puedes eliminar la columna original si no la necesitas)\n",
    "    df_tmdb = pd.concat([df_tmdb, encoded_df], axis=1)\n",
    "# 4. (Opcional) Eliminar columnas originales si ya no son necesarias\n",
    "df_tmdb.drop(columns=cols_to_encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683258d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122681, 430)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20b6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\")\n",
    "lang_encoded = ohe.fit_transform(df_tmdb[['original_language']])\n",
    "joblib.dump(ohe, \"original_language_ohe.pkl\")\n",
    "lang_encoded_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "    lang_encoded, index=df_tmdb.index, columns=[f\"lang_{cat}\" for cat in ohe.categories_[0]]\n",
    ")\n",
    "df_tmdb = pd.concat([df_tmdb, lang_encoded_df], axis=1)\n",
    "df_tmdb.drop(columns=['original_language'], inplace=True)  # opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859369ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb['adult'] = df_tmdb['adult'].astype(int)  # True → 1, False → 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ef2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb['release_date'] = pd.to_datetime(df_tmdb['release_date'], errors='coerce')\n",
    "df_tmdb['release_year'] = df_tmdb['release_date'].dt.year.fillna(0).astype(int)\n",
    "df_tmdb.drop(columns=['release_date'], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e0c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numeric_minmax_scaler.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "numeric_cols = ['vote_average', 'vote_count', 'runtime_tmdb', 'budget_tmdb', 'popularity', 'release_year']\n",
    "scaler = MinMaxScaler()\n",
    "df_tmdb[numeric_cols] = scaler.fit_transform(df_tmdb[numeric_cols])\n",
    "joblib.dump(scaler, \"numeric_minmax_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44deb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb.drop(columns=['imdb_id'], inplace=True)  # opcional, si no necesitas el ID de IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8588a5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122681 entries, 0 to 122680\n",
      "Columns: 569 entries, vote_average to release_year\n",
      "dtypes: Sparse[float64, 0](141), Sparse[int64, 0](417), float64(7), int64(4)\n",
      "memory usage: 17.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_tmdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c53d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Elimina columnas tipo object (como textos, listas, etc.)\n",
    "df_numeric = df_tmdb.select_dtypes(include=['number', 'Sparse'])\n",
    "\n",
    "# Convierte solo las columnas numéricas a sparse\n",
    "X_num_sparse = csr_matrix(df_numeric.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc19aebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122681, 569)\n",
      "(7, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_num_sparse.shape)   # Debería ser (122681, algo)\n",
    "print(vocab_vect.shape)     # Debería ser (122681, algo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99a12e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 47888 stored elements and shape (7, 10000)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "242c1734",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatching dimensions along axis 0: {122681, 7}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hstack\n\u001b[32m      3\u001b[39m X_num_sparse = csr_matrix(df_tmdb)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_combined = \u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_vect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_num_sparse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/scipy/sparse/_construct.py:756\u001b[39m, in \u001b[36mhstack\u001b[39m\u001b[34m(blocks, format, dtype)\u001b[39m\n\u001b[32m    754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_spmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/scipy/sparse/_construct.py:931\u001b[39m, in \u001b[36m_block\u001b[39m\u001b[34m(blocks, format, dtype, return_spmatrix)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    927\u001b[39m     \u001b[38;5;28mall\u001b[39m(issparse(b) \u001b[38;5;129;01mand\u001b[39;00m b.format == \u001b[33m'\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks.flat)\n\u001b[32m    928\u001b[39m ):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m N > \u001b[32m1\u001b[39m:\n\u001b[32m    930\u001b[39m         \u001b[38;5;66;03m# stack along columns (axis 1): must have shape (M, 1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m         blocks = \u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_stack_along_minor_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    932\u001b[39m         blocks = np.asarray(blocks, dtype=\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    934\u001b[39m     \u001b[38;5;66;03m# stack along rows (axis 0):\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/scipy/sparse/_construct.py:931\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    927\u001b[39m     \u001b[38;5;28mall\u001b[39m(issparse(b) \u001b[38;5;129;01mand\u001b[39;00m b.format == \u001b[33m'\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks.flat)\n\u001b[32m    928\u001b[39m ):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m N > \u001b[32m1\u001b[39m:\n\u001b[32m    930\u001b[39m         \u001b[38;5;66;03m# stack along columns (axis 1): must have shape (M, 1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m         blocks = [[\u001b[43m_stack_along_minor_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M)]\n\u001b[32m    932\u001b[39m         blocks = np.asarray(blocks, dtype=\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    934\u001b[39m     \u001b[38;5;66;03m# stack along rows (axis 0):\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/scipy/sparse/_construct.py:672\u001b[39m, in \u001b[36m_stack_along_minor_axis\u001b[39m\u001b[34m(blocks, axis)\u001b[39m\n\u001b[32m    670\u001b[39m other_axis_dims = {b._shape_as_2d[other_axis] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks}\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(other_axis_dims) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mMismatching dimensions along axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother_axis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    673\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother_axis_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    674\u001b[39m constant_dim, = other_axis_dims\n\u001b[32m    676\u001b[39m \u001b[38;5;66;03m# Do the stacking\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Mismatching dimensions along axis 0: {122681, 7}"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "X_num_sparse = csr_matrix(df_tmdb)\n",
    "X_combined = hstack((vocab_vect, X_num_sparse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba885ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "model.fit(X_combined)\n",
    "joblib.dump(model, 'nearest_neighbors_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time  # solo para simular retraso, quitar en producción\n",
    "\n",
    "# Supongamos que preparar X_combined es un proceso con loop\n",
    "# Aquí simulo con un loop dummy para mostrar tqdm\n",
    "for _ in tqdm(range(100), desc='Entrenando NearestNeighbors'):\n",
    "    time.sleep(0.01)  # simula trabajo pesado\n",
    "\n",
    "# Aquí ya tienes X_combined preparado, entrenas el modelo normalmente\n",
    "model = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "model.fit(X_combined)\n",
    "\n",
    "joblib.dump(model, 'nearest_neighbors_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
